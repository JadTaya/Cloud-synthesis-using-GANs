{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the train and test datasets and running statistics on them\n",
    "- You can uncomment a whole cell by pressing ctrl+A (while inside the cell) and then pressing ctrl+/\n",
    "- The cells are greyed out to not accidentally run them, since we only wanted to run each cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "import time\n",
    "from scipy import io\n",
    "import scipy.stats as stats  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the train and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##ONLY RUN ONCE\n",
    "\n",
    "# loaded = io.loadmat('clouds/2D_zeroPadaed_clouds_orig.mat')\n",
    "# total_clouds = [value for key, value in loaded.items() if key.startswith(\"cloud_\")]\n",
    "# clouds = [cloud for cloud in total_clouds if (np.count_nonzero(cloud) > 200)] #remove clouds that are nearly empty\n",
    "# print(total_clouds[0].shape)\n",
    "# print(\"Number of total clouds: \" + str(len(total_clouds))) \n",
    "# print(\"Number of non-empty clouds: \" + str(len(clouds)))\n",
    "# tensor_clouds = torch.Tensor(clouds) # transform to torch tensor\n",
    "# tensor_clouds = tensor_clouds.unsqueeze(1)\n",
    "\n",
    "# # Create the dataset\n",
    "# dataset = torch.utils.data.TensorDataset(tensor_clouds)\n",
    "\n",
    "# train_size = int(0.9 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "# torch.save(train_dataset, os.path.join(os.getcwd() + '/dataset' , 'train.pt'))\n",
    "# torch.save(test_dataset, os.path.join(os.getcwd() + '/dataset' , 'test.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betas mean\n",
    "- Calculate the mean of the betas in each image.\n",
    "- Find the gamma parameters that fit this distribution.\n",
    "- Plot the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'train.pt'))\n",
    "# train_size = len(train_dataset)\n",
    "# betas = []\n",
    "# for i in range(train_size):\n",
    "#     for j in range(130):\n",
    "#         for k in range(80):\n",
    "#             if train_dataset[i][0][0][j][k] != 0:\n",
    "#                betas.append(train_dataset[i][0][0][j][k])\n",
    "# np_betas = [x.numpy() for x in betas]\n",
    "# np_betas = np.array(np_betas, dtype=np.float32)\n",
    "# io.savemat('betas.mat', {'np_betas': np_betas})\n",
    "# fit_alpha, fit_loc, fit_beta=stats.gamma.fit(np_betas)\n",
    "# gamma_para = [fit_alpha, fit_loc, fit_beta]\n",
    "# io.savemat('gamma.mat', {'gamma_para': gamma_para})\n",
    "# np_betas = io.loadmat('betas.mat')['np_betas']\n",
    "# hist, bin_edges = np.histogram(np_betas, density=True)\n",
    "# plt.plot(hist) # plotting by columns\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'test.pt'))\n",
    "# test_size = len(test_dataset)\n",
    "# betas = []\n",
    "# for i in range(test_size):\n",
    "#     for j in range(130):\n",
    "#         for k in range(80):\n",
    "#             if test_dataset[i][0][0][j][k] != 0:\n",
    "#                betas.append(test_dataset[i][0][0][j][k])\n",
    "# np_betas = [x.numpy() for x in betas]\n",
    "# np_betas = np.array(np_betas, dtype=np.float32)\n",
    "# io.savemat('betas_test.mat', {'np_betas': np_betas})\n",
    "# fit_alpha, fit_loc, fit_beta=stats.gamma.fit(np_betas)\n",
    "# gamma_para = [fit_alpha, fit_loc, fit_beta]\n",
    "# io.savemat('gamma_test.mat', {'gamma_para': gamma_para})\n",
    "# np_betas = io.loadmat('betas_test.mat')['np_betas']\n",
    "# hist, bin_edges = np.histogram(np_betas, density=True)\n",
    "# plt.plot(hist) # plotting by columns\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0004)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_alpha, train_loc, train_beta  = io.loadmat('gamma.mat')['gamma_para'][0]\n",
    "# train_prob = torch.distributions.gamma.Gamma(train_alpha, train_beta, validate_args=None)\n",
    "# #\n",
    "# test_alpha, test_loc, test_beta  = io.loadmat('gamma_test.mat')['gamma_para'][0]\n",
    "# test_prob = torch.distributions.gamma.Gamma(test_alpha, test_beta, validate_args=None)\n",
    "\n",
    "# torch.distributions.kl.kl_divergence(test_prob, train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0004)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.distributions.kl.kl_divergence(train_prob,test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some beta stats for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'test.pt'))\n",
    "# test_size = len(test_dataset)\n",
    "# sa = []\n",
    "# for i in test_dataset:\n",
    "#     sa.append(i[0][0])\n",
    "# data_Tensor = torch.stack(sa,0)\n",
    "\n",
    "# var = torch.var(data_Tensor)\n",
    "# mean = torch.mean(data_Tensor)\n",
    "# data_min = torch.min(data_Tensor)\n",
    "# data_max = torch.max(data_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'test.pt'))\n",
    "# test_size = len(test_dataset)\n",
    "# mins = []\n",
    "# for i in range(test_size):\n",
    "#     tmp = 100000\n",
    "#     for j in range(130):\n",
    "#         for k in range(80):\n",
    "#             if test_dataset[i][0][0][j][k] != 0 and test_dataset[i][0][0][j][k] < tmp:\n",
    "#                 tmp =  test_dataset[i][0][0][j][k]\n",
    "#     mins.append(tmp)\n",
    "# mins = [x.numpy() for x in mins]\n",
    "# mins = np.array(mins, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-zero elements in the training set.\n",
    "- Count the number of non-zero elements in every image.\n",
    "- Subtract 201 and find the gamma parameters that fit this distribution.\n",
    "- Plot the histogram and save the gamma parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'train.pt'))\n",
    "# train_size = len(train_dataset)\n",
    "\n",
    "# non_zero_count_real = []\n",
    "# for i in range(train_size):\n",
    "#     non_zero_count_real.append(torch.count_nonzero(train_dataset[i][0]))\n",
    "    \n",
    "# non_zero_count_real = torch.stack(non_zero_count_real).numpy()\n",
    "# #substract 201 so that it starts from 0\n",
    "# non_zero_count_real = np.subtract(non_zero_count_real, 201.0)\n",
    "\n",
    "# plt.hist(non_zero_count_real, bins = 120)\n",
    "# plt.title('Training images')\n",
    "# plt.xlabel(r'$\\mathrm{(Shifted\\ left)\\ Non-zero\\ count\\ of\\:}\\ \\beta$')\n",
    "\n",
    "\n",
    "# fit_alpha, fit_loc, fit_beta=stats.gamma.fit(non_zero_count_real)\n",
    "# non_zero_train_gamma = [fit_alpha, fit_loc, fit_beta]\n",
    "# io.savemat('non_zero_train_gamma.mat', {'non_zero_train_gamma': non_zero_train_gamma})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'test.pt'))\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "non_zero_count_real_test = []\n",
    "for i in range(test_size):\n",
    "    non_zero_count_real_test.append(torch.count_nonzero(test_dataset[i][0]))\n",
    "    \n",
    "\n",
    "non_zero_count_real_test = torch.stack(non_zero_count_real_test).numpy()\n",
    "\n",
    "\n",
    "fit_alpha, fit_loc, fit_beta=stats.gamma.fit(non_zero_count_real_test)\n",
    "non_zero_test_gamma = [fit_alpha, fit_loc, fit_beta]\n",
    "io.savemat('non_zero_test_gamma.mat', {'non_zero_test_gamma': non_zero_test_gamma})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0154)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_alpha, train_loc, train_beta  = io.loadmat('non_zero_train_gamma.mat')['non_zero_train_gamma'][0]\n",
    "train_prob = torch.distributions.gamma.Gamma(train_alpha, train_beta, validate_args=None)\n",
    "#\n",
    "test_alpha, test_loc, test_beta  = io.loadmat('non_zero_test_gamma.mat')['non_zero_test_gamma'][0]\n",
    "test_prob = torch.distributions.gamma.Gamma(test_alpha, test_beta, validate_args=None)\n",
    "\n",
    "torch.distributions.kl.kl_divergence(test_prob, train_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some beta stats for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(os.path.join(os.getcwd() + '/dataset' , 'train.pt'))\n",
    "train_size = len(train_dataset)\n",
    "sa = []\n",
    "for i in train_dataset:\n",
    "    sa.append(i[0][0])\n",
    "data_Tensor = torch.stack(sa,0)\n",
    "\n",
    "var = torch.var(data_Tensor)\n",
    "mean = torch.mean(data_Tensor)\n",
    "data_min = torch.min(data_Tensor)\n",
    "data_max = torch.max(data_Tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
